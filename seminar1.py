# -*- coding: utf-8 -*-
"""seminar1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ep0btDeJge6lPKJShCIbdeQvfT5NjW3Q
"""

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

"""Задача: предсказать температуру плавления для белков по их аминокислотным последовательностям."""

import pandas as pd
#библиотека для загрузки, редактирования и создания табличных данных

df = pd.read_csv('tm.csv')

df

from matplotlib import pyplot as plt
df['pH'].plot(kind='hist', bins=20, title='pH')
plt.gca().spines[['top', 'right',]].set_visible(False)

df.columns

df.index

new_df = df[['protein_sequence','pH', 'tm']]

new_df.iloc[[0, 1, 2, 3]] # по номеру строки
new_df.loc[[0, 1, 2, 3]] # по названию строк

filtered_df = new_df[new_df['pH'] == 7]

new_df['pH'] == 7

test_seq = filtered_df['protein_sequence'].iloc[0]

test_seq

l = list()  #список: индексация
l = []

d = {}    # словарь  ключ(уникальный) : значение
d = dict()

t = ()    #кортеж:  один раз создали и не можете изменить
t = tuple()

s = set()  # множество  можете закинуть туда уникальные значения, нет индексации

def getOneHot(seq):
  amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
  #amino_acid_dict = {aa: 0 for aa in amino_acids}
  amino_acid_dict = {}
  for i in amino_acids:
    amino_acid_dict[i]  = 0

  for aa in seq:
    amino_acid_dict[aa] += 1
  #dict = {key: value}
  onehot = list(amino_acid_dict.values())
  #print(amino_acid_dict.keys())
  #print(amino_acid_dict.values())
  return onehot

getOneHot(test_seq)

filtered_df['onehot'] = filtered_df['protein_sequence'].apply(getOneHot)

getOneHot(filtered_df['protein_sequence'].iloc[3])

filtered_df

import numpy as np # библиотека для работы с массивами\векторами и математические операции : pandas это дополнение к нумпи

y = np.array(filtered_df['tm'])
X = np.array(filtered_df['onehot'])

x_new = []


x_old = X
for i in X:
  x_new.append(np.array(i))

X = np.array(x_new)

x_old

X

# y = f(X)
# y - melting temp  X - one hot sequence

len(X)

len(y)

"""
X1 y1
X2 y2

Xn yn
"""



from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify = None, random_state=42)

print(len(X_train), len(X_test))



from sklearn.linear_model import LinearRegression

LinReg_model = LinearRegression().fit(X_train, y_train)

y_pred = LinReg_model.predict(X_test)

from sklearn.metrics import r2_score, mean_squared_error

mean_squared_error(y_test, y_pred)

r2_score(y_test, y_pred)

y_pred

import plotly.express as px
import plotly.graph_objects as go
x_axis = np.arange(len(y_pred))
f1 = go.Figure(
    data = [
        go.Scatter(x=x_axis, y=np.abs(y_pred - y_test), name="mae")
    ],
    layout = {"xaxis": {"title": "num"}, "yaxis": {"title": "temp"}, "title": "MAGIC"}
)
f1

from sklearn.ensemble import RandomForestRegressor

RGReg_model = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_train, y_train)

y_pred_rf = RGReg_model.predict(X_test)

mean_squared_error(y_test, y_pred_rf)

import plotly.express as px
import plotly.graph_objects as go
x_axis = np.arange(len(y_pred))
f1 = go.Figure(
    data = [
        go.Scatter(x=x_axis, y=np.abs(y_pred_rf - y_test), name="mae")
    ],
    layout = {"xaxis": {"title": "num"}, "yaxis": {"title": "temp"}, "title": "MAGIC"}
)
f1

import plotly.express as px
import plotly.graph_objects as go
x_axis = np.arange(len(y_pred))
f1 = go.Figure(
    data = [
        go.Scatter(x=x_axis, y=y_pred, name="predicted"),
        go.Scatter(x=x_axis, y=y_test, name="groundtruth"),
    ],
    layout = {"xaxis": {"title": "num"}, "yaxis": {"title": "temp"}, "title": "MAGIC"}
)
f1

!pip install LightGBM

import lightgbm as lgbm


LGBM_model = lgbm.LGBMRegressor().fit(X_train, y_train)

y_pred_lgbm = LGBM_model.predict(X_test)

mean_squared_error(y_test, y_pred_lgbm)

import plotly.express as px
import plotly.graph_objects as go
x_axis = np.arange(len(y_pred))
f1 = go.Figure(
    data = [
        go.Scatter(x=x_axis, y=np.abs(y_pred_lgbm - y_test), name="mae")
    ],
    layout = {"xaxis": {"title": "num"}, "yaxis": {"title": "temp"}, "title": "MAGIC"}
)
f1

!pip install optuna

# prompt: Optimize LightGBM using Optuna

import optuna
from sklearn.metrics import mean_squared_error

def objective(trial):
    params = {
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'num_leaves': trial.suggest_int('num_leaves', 31, 127),
        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),
    }

    model = lgbm.LGBMRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    return rmse

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)

print('Best trial:')
trial = study.best_trial
print('  Value: {}'.format(trial.value))
print('  Params: ')
for key, value in trial.params.items():
    print('    {}: {}'.format(key, value))

best_params = study.best_params
optimized_lgbm_model = lgbm.LGBMRegressor(**best_params)
optimized_lgbm_model.fit(X_train, y_train)
y_pred_optimized_lgbm = optimized_lgbm_model.predict(X_test)
mse_optimized_lgbm = mean_squared_error(y_test, y_pred_optimized_lgbm)
print(f"Mean Squared Error with Optimized LGBM: {mse_optimized_lgbm}")

from matplotlib import pyplot as plt
filtered_df['tm'].plot(kind='hist', bins=10, title='tm')
plt.gca().spines[['top', 'right',]].set_visible(False)

filtered_df



